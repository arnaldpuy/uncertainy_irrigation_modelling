---
title: "Uncertainty in global irrigation water use persists after 50 years of research"
subtitle: "R code"
author: "Arnald Puy"
header-includes:
  - \usepackage[font=footnotesize]{caption}
  - \usepackage{dirtytalk}
  - \usepackage{booktabs}
  - \usepackage{tabulary}
  - \usepackage{enumitem}
  - \usepackage{lmodern}
  - \usepackage{amsmath}
  - \usepackage{mathtools}
  - \usepackage[T1]{fontenc}
  - \usepackage{tikz}
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
    keep_tex: true
  word_document:
    toc: no
    toc_depth: '2'
  html_document:
    keep_md: true
link-citations: yes
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = "pdf", cache = TRUE)
```

\newpage

# Preliminary functions

```{r, warning=FALSE, message=FALSE}

#   PRELIMINARY FUNCTIONS #######################################################

sensobol::load_packages(c("openxlsx", "data.table", "tidyverse","cowplot", 
                          "benchmarkme", "parallel", "wesanderson", "scales", "ncdf4", 
                          "countrycode", "rworldmap", "sp", "doParallel", "here", "lme4", 
                          "microbenchmark", "mgcv", "brms", "randomForest", "here", 
                          "igraph", "ggraph"))

# Create custom theme -----------------------------------------------------------

theme_AP <- function() {
  theme_bw() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          legend.background = element_rect(fill = "transparent",
                                           color = NA),
          legend.key = element_rect(fill = "transparent",
                                    color = NA), 
          strip.background = element_rect(fill = "white"), 
          legend.text = element_text(size = 7.3), 
          axis.title = element_text(size = 10),
          legend.key.width = unit(0.4, "cm"), 
          legend.key.height = unit(0.4, "cm"), 
          legend.key.spacing.y = unit(0, "lines"),
          legend.box.spacing = unit(0, "pt"),
          legend.title = element_text(size = 7.3), 
          axis.text.x = element_text(size = 7), 
          axis.text.y = element_text(size = 7), 
          axis.title.x = element_text(size = 7.3), 
          axis.title.y = element_text(size = 7.3),
          plot.title = element_text(size = 8),
          strip.text.x = element_text(size = 7.4), 
          strip.text.y = element_text(size = 7.4)) 
}

# Select color palette ----------------------------------------------------------

selected.palette <- "Darjeeling1"
```

```{r source_functions, warning=FALSE, message=FALSE, results="hide"}

# SOURCE ALL R FUNCTIONS NEEDED FOR THE STUDY ###################################

# Source all .R files in the "functions" folder --------------------------------

r_functions <- list.files(path = here("functions"), pattern = "\\.R$", full.names = TRUE)
lapply(r_functions, source)

```

# Bibliographical study

```{r naomi_data}

# NAOMI DATASET ################################################################

references.projected <- data.table(read.xlsx("./data/references_projection.xlsx")) %>%
  .[, focus:= "projected"]

references.current <- data.table(read.xlsx("./data/references_current.xlsx")) %>%
  .[, focus:= "current"]

references.full.dt <- rbind(references.projected, references.current) %>%
  .[, study:= paste(author, model, climate.scenario, sep = ".")] 

# CLEAN THE DATASET ############################################################

colnames_vector <- c("title", "author", "region")

# Remove leading and trailing spaces -------------------------------------------

references.full.dt[, (colnames_vector):= lapply(.SD, trimws), .SDcols = (colnames_vector)]
references.full.dt[, (colnames_vector):= lapply(.SD, str_squish), .SDcols = (colnames_vector)]

# Lowercaps --------------------------------------------------------------------

references.full.dt[, (colnames_vector):= lapply(.SD, tolower), .SDcols = (colnames_vector)]

# Remove multiple spaces -------------------------------------------------------

references.full.dt[, (colnames_vector):= lapply(.SD, function(x) 
  gsub("\\s+", " ", x)), .SDcols = (colnames_vector)]

# Correct America --------------------------------------------------------------

references.full.dt[, region:= ifelse(region == "america", "americas", region)]

# Extract the publication year -------------------------------------------------

references.full.dt[, publication.date:= str_extract(author, "\\d{4}")] %>%
  .[, publication.date:= as.numeric(publication.date)]
```

```{r naomi_features, dependson="naomi_data", fig.height=1.8, fig.width=2}

# FEATURES OF THE DATASET ######################################################

# Definition of target years ---------------------------------------------------

target_year <- c(2000, 2010, 2050, 2070, 2100)

# Name of different studies ----------------------------------------------------

sort(unique(references.full.dt[variable == "iww" & region == "global", title]))

# Number of data points --------------------------------------------------------

nrow(references.full.dt[variable == "iww" & region == "global"])

# Number of different studies per variable ---------------------------------------

references.full.dt[region == "global", unique(title), variable] %>%
  .[, .N, variable]

# Number of data points for each target year -----------------------------------

references.full.dt[variable == "iww" & region == "global" & 
                     estimation.year %in% target_year, .N, estimation.year]

# Number of unique studies estimating for each target year ---------------------

references.full.dt[variable == "iww" & region == "global" & 
                     estimation.year %in% target_year, unique(title), estimation.year] %>%
  .[, .N, estimation.year]

# Number of data points for every targeted year -----------------------------

references.full.dt[variable == "iww" & region == "global", .N, estimation.year] %>%
  .[order(estimation.year)]

# Cumulative sum of published studies ------------------------------------------

cumulative.iww <- references.full.dt[, .(title, publication.date, variable)] %>%
  .[variable == "iww"] %>%
  .[!duplicated(.)] %>%
  setorder(., publication.date) %>%
  .[, .N, publication.date] %>%
  .[, cumulative_sum := cumsum(N)] %>%
  ggplot(., aes(publication.date, cumulative_sum)) +
  geom_line() + 
  scale_x_continuous(breaks = breaks_pretty(n = 3)) +
  geom_point(size = 0.7) + 
  theme_AP() + 
  labs(x = "Publication year", y = "Nº studies")

cumulative.iww
```

```{r histogram_data_points, dependson="naomi_data", fig.height=2, fig.width=2}

# DISTRIBUTION OF DATA POINTS THROUGH YEARS @###################################

plot.bar <- references.full.dt[variable == "iww" & region == "global", .N, estimation.year] %>%
  ggplot(., aes(estimation.year, N)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = breaks_pretty(n = 3)) +
  labs(x = "Estimation year", y = "Nº data points") +
  theme_AP()

plot.bar
```

```{r plot_naomi, dependson="naomi_data", fig.height=3.5, fig.width=6}

# PLOT ALL ESTIMATIONS #########################################################

def.alpha <- 0.2

plot.iww <- references.full.dt[variable == "iww" & region == "global"] %>%
  .[, .(author, study, estimation.year, value)] %>%
  na.omit() %>%
  ggplot(., aes(estimation.year, value, color = author, group = study)) +
  geom_point(alpha = def.alpha, size = 0.5) +
  labs(x = "Estimation year", y = bquote("Km"^3)) +
  scale_color_discrete(name = "") +
  geom_line(alpha = def.alpha) +
  theme_AP() +
  guides(color = guide_legend(ncol = 2)) +
  theme(legend.text = element_text(size = 5.5), 
        legend.key.width = unit(0.25, "cm"), 
          legend.key.height = unit(0.25, "cm"))

plot.iww

references.full.dt[variable == "iwc" & region == "global"] %>%
  .[, .(author, study, estimation.year, value)] %>%
  na.omit() %>%
  ggplot(., aes(estimation.year, value, color = author, group = study)) +
  geom_point(alpha = def.alpha, size = 0.2) +
  labs(x = "Year", y = bquote("Km"^3)) +
  scale_color_discrete(name = "") +
  geom_line(alpha = def.alpha) +
  theme_AP()

```

```{r plot_iww_below, dependson="plot_naomi", fig.height=7, fig.width=6}

plot.iww + 
  theme(legend.position = "bottom", 
        legend.text = element_text(size = 4.8))
```

```{r plot.models, dependson="naomi_features", fig.height=4, fig.width=3}
 
# PLOT NUMBER OF UNIQUE STUDIES PER MODEL ######################################

plot.models <- references.full.dt[variable == "iww" & region == "global"] %>%
  .[, .(title, doi, model)] %>%
  .[, model:= tolower(model)] %>%
  .[, unique(doi), model] %>%
  .[, model := gsub("(?i)watergap\\s*\\d*\\.?\\d*", "watergap", model, perl = TRUE)] %>%
  .[, .N, model]  %>%
  .[, model:= ifelse(is.na(model), "No info", model)] %>%
  ggplot(., aes(reorder(model, N), N)) +
  geom_bar(stat = "identity") + 
  labs(x = "", y = "Nº studies") +
  coord_flip() +
  theme_AP() + 
  theme(axis.text.y = element_text(size = 5.5))

plot.models
```

```{r plot_examples, fig.height=3, fig.width=1.5}

# PLOT EXAMPLES TO ILLUSTRATE APPROACH #########################################

# Set seed for reproducibility -------------------------------------------------

set.seed(123)

# Create datasets for different SD trends --------------------------------------

data_increasing <- data.frame(
  period = rep(c("1990-2000", "2000-2010", "2010-2020"), times = c(5, 7, 4)),  
  value = c(rnorm(5, mean = 5, sd = 0.3),  # Low SD
            rnorm(7, mean = 7, sd = 0.8),  # Medium SD
            rnorm(4, mean = 6, sd = 1.5))  # High SD
)

data_decreasing <- data.frame(
  period = rep(c("1980-2000", "2000-2020"), times = c(5, 7)),  
  value = c(rnorm(5, mean = 5, sd = 1.5),  # High SD
            rnorm(7, mean = 7, sd = 0.8))  # Medium
)

data_invertedV <- data.frame(
  period = rep(c("1990-2000", "2000-2010", "2010-2020"), times = c(5, 7, 4)),  
  value = c(rnorm(5, mean = 5, sd = 0.4),  # Low SD
            rnorm(7, mean = 7, sd = 1.4),  # High SD (peak in the middle)
            rnorm(4, mean = 5, sd = 0.4))  # Low SD again
)

# Function to compute SD and create a ggplot -----------------------------------

create_plot <- function(data, title) {
  sd_values <- data %>%
    group_by(period) %>%
    summarize(sd_value = sd(value) + 3)
  
  ggplot(data, aes(x = period, y = value)) +
    geom_point(size = 1) +
    geom_point(data = sd_values, aes(x = period, y = sd_value), color = "red", size = 1.5) +  # SD as red dots
    geom_line(data = sd_values, aes(x = period, y = sd_value, group = 1), color = "red", linewidth = 1) +  # Line connecting SD values
    theme_AP() +
    theme(axis.text.x = element_text(size = 5.35), 
          plot.margin = unit(c(0.1, 0.1, 0, 0.1), "cm")) +
    scale_y_continuous(breaks = breaks_pretty(n = 3)) +
    labs(x = "", y = "Value") 
}

# Generate the three plots -----------------------------------------------------

p1 <- create_plot(data_increasing) 
p2 <- create_plot(data_decreasing)
p3 <- create_plot(data_invertedV)

# Merge using plot_grid --------------------------------------------------------

plot.examples.trends.data <- plot_grid(p1, p2, p3, ncol = 1, labels = c("e", "", ""))
plot.examples.trends.data
```

## The garden of forking paths

```{r plotting_forks}

# GRAPHICAL REPRESENTATION OF THE GARDEN OF FORKING PATHS ######################

# Define size of nodes ---------------------------------------------------------

size.nodes <- 1.5

# Create a balanced binary tree with height 3 ----------------------------------

tree <- make_tree(15, children = 2, mode = "out")

# Create a tree plot with all edges highlighted in red -------------------------

all.paths <- ggraph(tree, layout = "dendrogram") +
  geom_edge_link(color = "red", width = 1) +
  geom_node_point(size = size.nodes, color = "red") +
  theme_AP() +
  labs(x = "", y = "") +
  theme(legend.position = "none", 
        axis.ticks = element_blank(), 
        axis.text.x = element_blank(), 
        axis.text.y = element_blank())

all.paths

# Create a tree plot with only one analytical path highlighted -----------------

# Define the path to highlight (from root to a specific node) ------------------

highlight_nodes <- c(1, 2, 5, 11)  # Path: 1 → 2 → 5 → 11

highlight_edges <- apply(cbind(head(highlight_nodes, -1), 
                               tail(highlight_nodes, -1)), 1, function(x) 
                                 paste(x, collapse = "-"))

# Assign default colors (black) to all edges and nodes -------------------------

E(tree)$edge_color <- "black"
V(tree)$node_color <- "black"

# Extract edges from the tree and match with highlight_edges -------------------

edge_list <- apply(get.edgelist(tree), 1, function(x) paste(x, collapse = "-"))
E(tree)$edge_color[edge_list %in% highlight_edges] <- "red"

# Highlight the selected nodes in red -___--------------------------------------

V(tree)$node_color[highlight_nodes] <- "red"

# Plot the tree with explicitly defined colors for both edges and nodes --------

one.path <- ggraph(tree, layout = "dendrogram") +
  geom_edge_link(aes(edge_color = edge_color), width = 1) +  # Correct edge colors
  geom_node_point(aes(color = node_color), size = size.nodes) +  # Correct node colors
  scale_edge_color_manual(values = c("black" = "black", "red" = "red")) +  # Fix for edges
  scale_color_manual(values = c("black" = "black", "red" = "red")) +  # Fix for nodes
  theme_AP() + 
  labs(x = "", y = "") +
  theme(legend.position = "none", 
        axis.ticks = element_blank(), 
        axis.text.x = element_blank(), 
        axis.text.y = element_blank())

one.path
```

```{r plot_forking_paths, dependson="plotting_forks", fig.height=1.5, fig.width=3}

# MERGE FORKING PATHS ##########################################################

plot_grid(one.path, all.paths, ncol = 2, labels = c("a", ""))
```

```{r forking_paths, dependson=c("naomi_data", "naomi_features")}

# DEFINE THE UNCERTAINTY SPACE ##################################################

# Target year ------------------------------------------------------------------

## Defined above

# Target year interval ---------------------------------------------------------

target_year_interval <- c("yes", "no")

# Interval publication ---------------------------------------------------------

interval <- c(10, 15, 20)

# Metrics of study -------------------------------------------------------------

metrics <- c("cv", "range", "sd", "var", "entropy", "iqr")

# Inclusion criteria -----------------------------------------------------------

exclude_before_1990 <- c("yes", "no")

# Rolling windows --------------------------------------------------------------

rolling_window_factor <- c(1, 0.5)

# Define the forking paths -----------------------------------------------------

forking_paths <- expand.grid(target_year = target_year,
                             target_year_interval = target_year_interval,
                             interval = interval,
                             exclude_before_1990 = exclude_before_1990,
                             rolling_window_factor = rolling_window_factor,
                             metric = c(metrics, paste(metrics, "_normalized", sep = ""))) %>%
  data.table()

# Number of simulations --------------------------------------------------------

nrow(forking_paths)

# RUN MODEL #####################################################################

# Select only simulations at the global level of iww ---------------------------

dt <- references.full.dt[variable == "iww" & region == "global"]

# Run simulations --------------------------------------------------------------

trend <- list()

for (i in 1:nrow(forking_paths)) {
  
  trend[[i]] <- forking_paths_fun(dt = dt,
                                  target_year = forking_paths[[i, "target_year"]], 
                                  target_year_interval = forking_paths[[i, "target_year_interval"]],
                                  interval = forking_paths[[i, "interval"]], 
                                  rolling_window_factor = forking_paths[[i, "rolling_window_factor"]],
                                  exclude_before_1990 = forking_paths[[i, "exclude_before_1990"]],
                                  metric = forking_paths[[i, "metric"]])
}
```

```{r naomi_arrange, dependson="forking_paths"}

# ARRANGE DATA ##################################################################

output.dt <- lapply(trend, function(x) x[["results"]]) %>%
  do.call(rbind, .) %>%
  data.table() %>%
  setnames(., "V1", "trend")

final.dt <- cbind(forking_paths, output.dt)

# Export simulations -----------------------------------------------------------

fwrite(final.dt, "forking.paths.dataset.csv")

# Print the fraction of simulations in each classification ---------------------

final.dt %>%
  .[, .(total = .N), trend] %>%
  .[, fraction:= total / nrow(output.dt)] %>%
  print()


# Now remove all simulations that produced just one single point ---------------

final.dt <- final.dt[!trend == "single point"]

# Simulations that did not lead to a reduction in uncertainty ------------------

final.dt %>%
  .[, .(total = .N), trend] %>%
  .[, fraction:= total / nrow(output.dt)] %>%
  .[!trend == "Descending"] %>%
  .[, sum(fraction)]
```

```{r examples_plots, dependson="forking_paths", fig.height=3.5, fig.width=3.5, warning=FALSE}

# PLOTS FORKING PATHS EXAMPLES ################################################

plots.dt <- lapply(trend, function(x) x[["plot"]]) 

random.plots <- c(1, 986, 345)
decreasing.plots <- c(1093, 556, 4)
increasing.plots <- c(10, 602, 770)

out.random <- out.decreasing <- out.increasing <- list()

for (i in 1:length(random.plots)) {
  
  out.random[[i]] <- plot_plots_forking_paths_fun(random.plots[i])
  out.decreasing[[i]] <- plot_plots_forking_paths_fun(decreasing.plots[i])
  out.increasing[[i]] <- plot_plots_forking_paths_fun(increasing.plots[i])
}

pt.random <- plot_grid(out.random[[1]] + geom_smooth() + labs(x = "", y = "+ Uncertainty"), 
                       out.random[[2]] + geom_smooth() + labs(x = "", y = ""), 
                       out.random[[3]] + geom_smooth() + labs(x = "", y = ""), 
                       ncol = 3)

pt.decreasing <- plot_grid(out.decreasing[[1]] + geom_smooth() + labs(x = "", y = "+ Uncertainty"), 
                           out.decreasing[[2]] + geom_smooth() + labs(x = "", y = ""), 
                           out.decreasing[[3]] + geom_smooth(method = "lm", se = F) + labs(x = "", y = ""), 
                           ncol = 3)

pt.increasing <- plot_grid(out.increasing[[1]] + geom_smooth(method = "lm", se = F), 
                           out.increasing[[2]] + geom_smooth() + labs(x = "Publication year", y = ""), 
                           out.increasing[[3]] + geom_smooth() + labs(x = "Publication year", y = ""), 
                           ncol = 3)

plot.examples.trends <- plot_grid(pt.random, pt.decreasing, pt.increasing, ncol = 1)
plot.examples.trends
```

```{r plot_results_forking_paths, dependson=c("naomi_arrange", "forking_paths"), fig.height=2.2, fig.width=3}

# PLOT RESULTS #################################################################

selected_colors <- c("Ascending" = "red", "Descending" = "darkgreen", "Random" = "orange")

plot.fraction <- final.dt[, .(total = .N), trend] %>%
  .[, fraction:= total / nrow(output.dt)] %>%
  ggplot(., aes(trend, fraction, fill = trend)) +
  geom_bar(stat = "identity") +
  labs(x = "", y = "Fraction simulations") +
  scale_fill_manual(values = selected_colors, name = "Uncertainty") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  theme_AP() + 
  theme(axis.ticks.x = element_blank(), 
        axis.text.x = element_blank(), 
        legend.position = "right")

plot.fraction 
```

```{r random_forest, dependson=c("naomi_arrange", "forking_paths"), fig.width=3.5, fig.height=2}

# RANDOM FOREST ################################################################

# Convert categorical variables to factors -------------------------------------

df <- data.frame(final.dt)
df$exclude_before_1990 <- as.factor(final.dt$exclude_before_1990)
df$metric <- as.factor(final.dt$metric)
df$trend <- as.factor(df$trend)
df$target_year_interval <- as.factor(df$target_year_interval)

# Train the model --------------------------------------------------------------

rf_model <- randomForest(trend ~ target_year + target_year_interval + interval + 
                           exclude_before_1990 + rolling_window_factor + metric, 
                         data = df, importance = TRUE)

# View variable importance -----------------------------------------------------

dt_rf_model <- data.frame(importance(rf_model))
dt_rf_model

# Plot -------------------------------------------------------------------------

plot.rf <- dt_rf_model %>%
  rownames_to_column(., var = "factors") %>%
  data.table() %>%
  setnames(., c("MeanDecreaseAccuracy", "MeanDecreaseGini"), 
           c("Accuracy", "Gini")) %>%
  melt(., measure.vars = c("Accuracy", "Gini")) %>%
  ggplot(., aes(reorder(factors, value), value)) +
  geom_point() +
  coord_flip() +
  facet_wrap(~variable) + 
  scale_y_continuous(breaks = breaks_pretty(n = 3)) +
  labs(x = "", y = "Mean decrease") +
  theme_AP()

plot.rf
```

```{r merge_fraction_rf, dependson=c("random_forest", "plot_results_forking_paths", "forking_paths"), fig.height=2.2, fig.width=6.3}

bottom <- plot_grid(cumulative.iww, plot.fraction, plot.rf, ncol = 3, labels = c("b", "c", "d"), 
          rel_widths = c(0.26, 0.3, 0.44))

bottom
```

```{r merge_fraction_trend, dependson=c("merge_fraction_rf", "plot_naomi", "forking_paths"), fig.height=5.8, fig.width=6}

# 
final.faceted.plot <- plot_grid(plot.iww, bottom, ncol = 1, labels = c("a", ""), 
                                rel_heights = c(0.55, 0.45))

final.faceted.plot

```

```{r plot_forking_paths_faceted, dependson=c("naomi_arrange", "forking_paths"), fig.height=4, fig.width=4}

# RESULTS FACETED BY INTERVAL AND TARGET YEAR, X AXIS METRICS ###################

plot.faceted.metrics <- final.dt %>%
  ggplot(., aes(x = factor(metric), fill = trend)) +
  geom_bar(position ="identity") +
  facet_grid(target_year ~ interval, scales = "free_y") +
  scale_fill_manual(values = selected_colors, name = "Uncertainty") +
  theme_AP() +
  labs(x = "Metric", y = "Nº simulations") +
  theme(legend.position = "none") +
  coord_flip()

plot.faceted.metrics
```


```{r final_final_merged, dependson = c("plot_naomi", "merge_fraction_rf", "random_forest", "forking_paths", "plot_results_forking_paths"), fig.height=7, fig.width=6.5}

bottom <- plot_grid(cumulative.iww, plot.fraction, ncol = 2, rel_widths = c(0.4, 0.6), 
                    labels = c("b", "c"))
left <- plot_grid(bottom, plot.rf, ncol = 1, labels = c("", "d"), rel_heights = c(0.6, 0.4))
bottom2 <- plot_grid(left, plot.faceted.metrics, ncol = 2, labels = c("", "e"))
plot_grid(plot.iww, bottom2, rel_heights = c(0.42, 0.58), ncol = 1, labels = c("a", ""))
```

```{r faceted_plot2, dependson = c("plot_naomi", "merge_fraction_rf", "random_forest", "forking_paths", "plot_results_forking_paths", "examples_plots"), fig.height=6.5, fig.width=5.99}

left <- plot_grid(cumulative.iww, plot.fraction, ncol = 1, rel_heights = c(0.4, 0.6), 
                  labels = c("b", "d"))
bottom <- plot_grid(left, plot.examples.trends, ncol = 2, rel_widths = c(0.3, 0.7), 
                    labels = c("", "c"))
plot_grid(plot.iww, bottom, ncol = 1, rel_heights = c(0.5, 0.5), labels = c("a", ""))
```

```{r faceted_plot3, dependson = c("plot_naomi", "merge_fraction_rf", "random_forest", "forking_paths", "plot_results_forking_paths", "examples_plots", "plot.models", "plot_examples", "histogram_data_points"), fig.height=6.5, fig.width=5.5}

left <- plot_grid(cumulative.iww, plot.bar, ncol = 1, labels = c("b", "c"))
bottom <- plot_grid(left, plot.models, ncol = 2, labels = c("", "d"), rel_widths = c(0.4, 0.6))
bottom.right <- plot_grid(bottom, plot.examples.trends.data, ncol = 2, rel_widths = c(0.7, 0.3))
plot_grid(plot.iww, bottom.right, ncol = 1, rel_heights = c(0.5, 0.5), labels = c("a", ""))
```

```{r faceted_plot, dependson="naomi_arrange", fig.height=3.8, fig.width=5.5}

# SENSITIVITY ANALYSIS PLOT BY FACET ###########################################

plot.sa.facet <- final.dt %>%
  melt(., measure.vars = c("target_year", "target_year_interval", "interval", 
                           "exclude_before_1990", "rolling_window_factor", "metric")) %>%
  .[, .N, .(variable, value, trend)] %>%
  .[ , value := gsub("_normalized", "_n", value)] %>%
  ggplot(., aes(value, N, fill = trend)) +
  scale_fill_manual(values = selected_colors, name = "Uncertainty") +
  geom_bar(stat = "identity", position = position_dodge(0.5)) +
  facet_wrap(~variable, scale = "free") +
  labs(x = "", y = "Nº simulations") +
  theme_AP() + 
  coord_flip() +
  theme(legend.position = "none")

plot.sa.facet
```

```{r sa_indices, dependson="naomi_arrange", fig.height=2, fig.width=3}

# PLOT AVERAGE MINIMAX AS SENSITVITY INDEX #####################################

plot.sa <- final.dt %>%
  melt(., measure.vars = c("target_year", "target_year_interval", "interval", 
                           "exclude_before_1990", "rolling_window_factor", "metric")) %>%
  .[, .N, .(variable, value, trend)] %>%
  .[, .(minimax = max(N) - min(N)), .(variable, trend)] %>%
  .[, .(mean = mean(minimax), 
        sd = sd(minimax)), variable] %>%
  ggplot(., aes(reorder(variable, mean), mean)) +
  geom_point() + 
  labs(x = "", y = "mean(minimax)") +
  coord_flip() + 
  theme_AP()

plot.sa
```

```{r merge_sa, dependson=c("faceted_plot", "plot_results_forking_paths"), fig.width=4.5, fig.height=4.5}

# MERGE SENSITIVITY ANALYSIS PLOTS #############################################

legend <- get_legend_fun(plot.fraction + theme(legend.position = "top"))
top <- plot_grid(plot.fraction + theme(legend.position = "none"), plot.sa, ncol = 2, 
                 rel_widths = c(0.4, 0.6), labels = c("a", "b"))
top.with.legend <- plot_grid(legend, top, rel_heights = c(0.1, 0.9), ncol = 1)
plot_grid(top.with.legend, plot.sa.facet, ncol = 1, rel_heights = c(0.38, 0.62), 
          labels = c("", "c"))
```
\newpage

# Session information

```{r session_information}

# SESSION INFORMATION ##########################################################

sessionInfo()

## Return the machine CPU ------------------------------------------------------

cat("Machine:     "); print(get_cpu()$model_name)

## Return number of true cores -------------------------------------------------

cat("Num cores:   "); print(detectCores(logical = FALSE))

## Return number of threads ---------------------------------------------------

cat("Num threads: "); print(detectCores(logical = FALSE))
```